#  Ghm-Data-CloudFunctions <img src="images/cloud_functions.png" alt="cloud_functions-logo" width="40"/>

## Sobre

Bem-vindo ao reposit√≥rio do Google Cloud Functions. Neste local, est√° dispon√≠vel uma cole√ß√£o abrangente de scripts e configura√ß√µes dedicados aos processos de extra√ß√£o de dados.

O Cloud Function √© uma forma de computa√ß√£o serverless oferecida pelo Google Cloud. Ele possibilita a execu√ß√£o de c√≥digo em resposta a eventos, sem a necessidade de provisionar ou gerenciar servidores. Essa abordagem permite a focaliza√ß√£o na l√≥gica de aplica√ß√£o, enquanto a plataforma cuida da infraestrutura subjacente.

Para aprofundar ainda mais o conhecimento sobre o Google Cloud Functions, recomenda-se consultar a documenta√ß√£o oficial:

- [Documenta√ß√£o oficial Google Cloud Functions](https://cloud.google.com/functions)

## Objetivo

Segue uma lista dos principais objetivos do Google Cloud Functions como ferramenta integrante do projeto de Dados.

O objetivo deste reposit√≥rio √© fornecer uma estrutura organizada para centralizar e versionar fun√ß√µes criadas no Cloud Functions, fornecendo solu√ß√µes eficientes para tarefas espec√≠ficas, eliminando a necessidade de gerenciar a infraestrutura subjacente. Cada fun√ß√£o √© projetada para realizar uma tarefa espec√≠fica de maneira r√°pida e eficaz, permitindo a execu√ß√£o de opera√ß√µes cr√≠ticas com o m√≠nimo de esfor√ßo poss√≠vel.


Os objetivos das Google Cloud Functions, que s√£o parte da oferta de computa√ß√£o sem servidor (serverless) do Google Cloud, incluem:

- **Automa√ß√£o de Tarefas**: Facilitar a automa√ß√£o de tarefas recorrentes e processos de back-end, como a manipula√ß√£o de eventos originados de outros servi√ßos do Google Cloud ou de fontes externas.

- **Escalabilidade Autom√°tica**: Escalar automaticamente de acordo com a demanda. Isso significa que as fun√ß√µes podem lidar com um n√∫mero elevado de solicita√ß√µes sem a necessidade de gerenciamento de infraestrutura.

- **Execu√ß√£o Baseada em Eventos**: Executar c√≥digo em resposta a eventos espec√≠ficos, como altera√ß√µes em dados no Google Cloud Storage, atualiza√ß√µes em um banco de dados do Firestore, ou mensagens recebidas em um t√≥pico do Pub/Sub.

- **Desenvolvimento √Ågil e Focado**: Permitir que os desenvolvedores se concentrem na escrita do c√≥digo que realmente importa para a aplica√ß√£o, sem se preocupar com o ambiente subjacente de execu√ß√£o, manuten√ß√£o de servidores, ou a complexidade da infraestrutura.

- **Integra√ß√£o com o Ecossistema Google Cloud**: Integrar-se perfeitamente com outros servi√ßos do Google Cloud, como BigQuery, Cloud Pub/Sub, Firebase, Cloud Storage, entre outros, proporcionando um desenvolvimento mais √°gil e eficiente.

- **Redu√ß√£o de Custo**: O modelo de pagamento √© baseado no uso real, o que pode ajudar a reduzir custos operacionais, pois n√£o h√° cobran√ßa quando as fun√ß√µes n√£o est√£o sendo executadas.

- **Rapidez na Implementa√ß√£o**: Capacidade de implementar rapidamente novas funcionalidades e l√≥gicas de neg√≥cios, acelerando o ciclo de desenvolvimento e entrega de produtos.

- **Isolamento e Seguran√ßa**: Cada fun√ß√£o √© executada em seu pr√≥prio ambiente isolado, o que aumenta a seguran√ßa e reduz os riscos de conflitos de depend√™ncias.

Esses objetivos refletem a natureza flex√≠vel, escal√°vel e eficiente das Google Cloud Functions, tornando-as uma ferramenta valiosa para desenvolvedores e empresas que buscam solu√ß√µes de cloud computing √°geis e eficientes.

## Organiza√ß√£o do Reposit√≥rio

O reposit√≥rio est√° organizado da seguinte maneira:

```bash
‚îú‚îÄ‚îÄ .github
‚îÇ   ‚îî‚îÄ‚îÄ workflows
‚îÇ       ‚îî‚îÄ‚îÄ ci-deploy-gcf-...
‚îú‚îÄ‚îÄ cloudfunctions
‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ folder_functions
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ source_code
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ files.py
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ deploy.sh
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ var_dev.sh
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ var_prd.sh
‚îÇ   ‚îú‚îÄ‚îÄ .python-version
‚îÇ   ‚îú‚îÄ‚îÄ poetry.lock
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml
```

### Estrutura das Pastas

- **.github/workflows/**: Cont√©m os scripts de CI/CD, incluindo o `ci-deploy-gcf-...` para automa√ß√£o do deploy das fun√ß√µes para o Google Cloud Functions via GitHub Actions.
  
- **cloudfunctions/src/**: Diret√≥rio principal das fun√ß√µes do Google Cloud Functions.

    - **folder_functions/**: Diret√≥rio que cont√©m o c√≥digo e os arquivos de configura√ß√£o de uma fun√ß√£o espec√≠fica. Cada fun√ß√£o segue o padr√£o:
  
        - **source_code/**: Pasta que cont√©m os scripts `.py` utilizados pela fun√ß√£o. Cada fun√ß√£o deve incluir um arquivo `requirements.txt` para definir as depend√™ncias.
        
        - **deploy.sh**: Script que realiza o deploy da fun√ß√£o no Google Cloud Functions. O processo foi automatizado via CI/CD.
        
        - **var_dev.sh**: Script que define as vari√°veis de ambiente para o ambiente de desenvolvimento (Dev).
        
        - **var_prd.sh**: Script que define as vari√°veis de ambiente para o ambiente de produ√ß√£o (Prod).
  
- **.python-version**: Arquivo que define a vers√£o do Python utilizada no projeto.
  
- **poetry.lock e pyproject.toml**: Arquivos de configura√ß√£o e gerenciamento de depend√™ncias do projeto Python utilizando o Poetry.

‚ö†Ô∏è **Observa√ß√µes**

- O processo de deploy das Cloud Functions √© totalmente automatizado atrav√©s dos scripts localizados no diret√≥rio `.github/workflows/`. Esses scripts utilizam o GitHub Actions para realizar o deploy de forma cont√≠nua.
  
- Cada fun√ß√£o dentro da pasta `src` segue um padr√£o de organiza√ß√£o para garantir consist√™ncia e facilidade na manuten√ß√£o.

# Uso

O uso das Google Cloud Functions envolve principalmente a automa√ß√£o e execu√ß√£o de c√≥digo em resposta a eventos espec√≠ficos dentro do ecossistema do Google Cloud ou de fontes externas. 

Alguns dos principais usos incluem:

- **Processamento de Eventos**: Executar fun√ß√µes em resposta a eventos de servi√ßos do Google Cloud, como upload de arquivos no Cloud Storage, mensagens no Pub/Sub, ou altera√ß√µes em bancos de dados do Firestore ou Realtime Database.

- **Integra√ß√µes e APIs**: Criar APIs ou microsservi√ßos que reagem a solicita√ß√µes HTTP, facilitando a integra√ß√£o com outras aplica√ß√µes ou servi√ßos.

- **Processamento de Dados**: Utilizar para processamento de dados em tempo real, como an√°lise, filtragem, e transforma√ß√£o de dados de entrada.

## Instala√ß√£o e Configura√ß√£o

Ao contr√°rio de muitos servi√ßos que demandam processos de instala√ß√£o, o Cloud Functions √© um servi√ßo serverless, eliminando completamente a necessidade de instala√ß√£o. Nesse contexto, basta concentrar-se na cria√ß√£o do c√≥digo e na configura√ß√£o da fun√ß√£o, podendo ser feita de maneira pr√°tica e eficiente, seja por meio do console do Google Cloud ou utilizando comandos diretamente no shell(sh). Esse paradigma simplificado permite um r√°pido desenvolvimento e implementa√ß√£o de fun√ß√µes, sem a complexidade associada √† configura√ß√£o e gest√£o de infraestrutura.

### Configura√ß√£o de Trigger com Autentica√ß√£o (Require Authentication)
Ao desenvolver Cloud Functions, √© uma boa pr√°tica incorporar autentica√ß√£o aos seus triggers. Isso significa que a execu√ß√£o da fun√ß√£o s√≥ ser√° permitida para solicita√ß√µes que apresentem credenciais ou tokens de autentica√ß√£o v√°lidos.

Para implementar essa pr√°tica, configure seu Cloud Functions para aceitar apenas solicita√ß√µes autenticadas marcando a op√ß√£o `Require Authentication` no processo de cria√ß√£o de uma fun√ß√£o no console Cloud Function, conforme ilustrado na imagem abaixo:

![Require Authentication](images/create_function.png "Criar fun√ß√£o com authentica√ß√£o")

‚ö†Ô∏è **Observa√ß√µes**: Caso o desenvolvimento sej√° feito utilizando os scripts de `deploy.sh` e `var_{env}.sh`, essa configura√ß√£o j√° estar√° pronta e n√£o ser√° necess√°rio ajustes adicionais.

Ap√≥s concluir o desenvolvimento da fun√ß√£o, √© essencial gerar um token ao realizar uma solicita√ß√£o. Recomenda-se consultar a documenta√ß√£o oficial do Google para obter orienta√ß√µes detalhadas sobre como gerar o token e realizar a autentica√ß√£o. As informa√ß√µes espec√≠ficas est√£o dispon√≠veis no link a seguir:
- [Documenta√ß√£o de Autentica√ß√£o do Google Cloud Functions.](https://cloud.google.com/functions/docs/securing/authenticating?hl=pt-br).

### Integra√ß√£o com Secret Manager

Ao implementar Cloud Functions que necessitem de armazenamento seguro de credenciais, chaves de API ou outros segredos sens√≠veis, √© altamente recomend√°vel seguir boas pr√°ticas de seguran√ßa. Uma maneira eficaz de gerenciar essas informa√ß√µes confidenciais √© atrav√©s do Google Cloud Secret Manager.
Para utilizar siga os seguintes passos:
1. Crie o secret no console do secret manager
2. Certifique-se que a conta de servi√ßo utilizada para executar jobs, possua a permiss√£o ``Secret Manager Secret Accessor`` no IAM (Identity and Access Management) do projeto comn-{env}.
Por padr√£o a conta utilizada √© a ``[project-number]-compute@developer.gserviceaccount.com``. Mas foi criada uma conta personalizada para esse intuito chamada `sa-cloudfunction@ghm-data-{env}.iam.gserviceaccount.com`.
3. Para concluir o restante da configura√ß√£o, siga as orienta√ß√µes detalhadas na documenta√ß√£o fornecida abaixo:
    - [Como utilizar secret no Cloud Functions](https://cloud.google.com/functions/docs/configuring/secrets?hl=pt-br)

üîó Para mais configura√ß√µes consulte [configurar o Cloud Function](https://cloud.google.com/functions/docs/configuring?hl=pt-br)

## Normas e Padr√µes

### Padr√µes de Nomenclatura

Ao criar uma fun√ß√£o no Cloud Functions, √© importante seguir padr√µes de nomenclatura consistentes para facilitar a identifica√ß√£o e a manuten√ß√£o.

Recomenda-se a seguinte estrutura de nome:

- lower case
- Separado por "_"
- Prefixo e placeholders: `gcf_{tipo de origem}_{aplica√ß√£o}_to_{zona}_{contexto_workload}`

Por exemplo: `gcf_api_inst_dr_osmar_to_bronze_atendimento`

### Par√¢metros de requisi√ß√£o

√â importante ressaltar que determinadas fun√ß√µes possuem a capacidade de receber par√¢metros de requisi√ß√£o diretamente a partir do request HTTP. Essa flexibilidade proporciona uma personaliza√ß√£o e adapta√ß√£o din√¢mica dessas fun√ß√µes √†s necessidades espec√≠ficas de cada solicita√ß√£o. A inclus√£o de par√¢metros nos requests permite a configura√ß√£o din√¢mica das fun√ß√µes, resultando em uma abordagem mais vers√°til e din√¢mica para o tratamento de dados e execu√ß√£o de tarefas. Essa flexibilidade amplia consideravelmente a gama de cen√°rios nos quais as fun√ß√µes podem ser aplicadas, elevando a efici√™ncia e a adaptabilidade do sistema como um todo.

Um exemplo concreto de uma fun√ß√£o que utiliza esse mecanismo √© a [gcf_api_inst_dr_osmar_to_bronze_agendamento](src/gcf_api_inst_dr_osmar_to_bronze_agendamento). Abaixo, √© apresentado um trecho do c√≥digo onde a vari√°vel **`request_json`** recebe os par√¢metros enviados pela solicita√ß√£o e, em seguida, descompacta esses par√¢metros em vari√°veis essenciais para o funcionamento da fun√ß√£o:

```python

def main(request=None):
  
    request_json = request.get_json(silent=True)

    # recover parameter values in request json
    leitura_diaria = request_json.get("leitura_diaria", False) if request_json else False

```

Aqui est√° um exemplo simples de requisi√ß√£o com argumentos:
```bash
curl -m 130 -X POST https://southamerica-east1-[PROJECT_ID].cloudfunctions.net/gcf_api_inst_dr_osmar_to_bronze_agendamento \
-H "Authorization: Bearer $(gcloud auth print-identity-token)" \
-H "Content-Type: application/json" \
-d '{
    "leitura_diaria": "True",
}'
```

## Orquestra√ß√£o

A orquestra√ß√£o de determinadas fun√ß√µes √© conduzida por meio do Cloud Composer (Apache Airflow).

### **Composer**
A orquestra√ß√£o do Cloud Function pode ser realizada de duas maneiras no Cloud Composer (Apache Airflow), utilizando templates ou desenvolvendo DAGs personalizadas.

Abaixo, est√° dispon√≠vel informa√ß√µes detalhadas e recursos espec√≠ficos para ambas as abordagens, oferecendo flexibilidade na integra√ß√£o e automa√ß√£o de fluxos de trabalho de processamento de dados no Dataproc usando o Composer.

#### **1. Utiliza√ß√£o de Templates**

No reposit√≥rio do Composer, foi simplificado a cria√ß√£o de DAGs atrav√©s do uso de templates que utilizam argumentos provenientes de um arquivo YAML. Abaixo, √© fornecido um exemplo de como configurar os argumentos relacionados ao Cloud Functions utilizando o template [`elt_data_pipeline.py`](..\composer\plugins\include\template\elt_data_pipeline.py). Este template desempenha um papel crucial na automatiza√ß√£o do processo Extract, Load, Transform (ELT) no ambiente do Cloud Composer.

Exemplo de configura√ß√£o para Cloud Function:

```yaml
tasks:
  - process: atendimento_diario # Nome que serve de base para o nome tabela bronze e silver, na silver √© aplicado um prefixo "tbl".
    source: api_inst_dr_osmar # Origem dos dados composto pela 'aplica√ß√£o' + 'sistema de origem'. Utilizaso para criar a nomenclatura dos datasets de origem e destino.
    deletion:
      deletion_partition_bronze: False # Habilita a dele√ß√£o de parti√ß√£o na tabela bronze
    ingestion:
      service: cloudfunctions
      function_name: gcf_api_inst_dr_osmar_to_bronze_atendimento
      request_method: POST
      data_request: {"leitura_diaria": True}
    # transformation:
    #   service: dataform
    #   silver_is_incremental: True
    dependencies:
      - atendimento
```
- Neste arquivo, a se√ß√£o **`cloudfunction`** √© utilizada para configurar operadores referentes ao Cloud Function.

Acesse o arquivo YAML completo no link abaixo: 
- **[conf_api_inst_dr_osmar_brz_to_slv_atendimento.yaml](..\composer\plugins\include\configs\api_inst_dr_osmar\conf_api_inst_dr_osmar_brz_to_slv_atendimento.yaml)**

#### Inserindo par√¢metros de requisi√ß√£o

No template `elt_data_pipeline`, os par√¢metros de requisi√ß√£o s√£o integrados ao arquivo YAML associado √† DAG, utilizando a chave `data_request`, conforme ilustrado no exemplo de c√≥digo acima, em conformidade com um formato predefinido. Posteriormente, esses argumentos s√£o anexados ao operador respons√°vel por invocar a Cloud Function.

Aqui est√° um exemplo pr√°tico utilizado pelo template no qual o Operador `HttpOperator` √© empregado para invocar uma Cloud Function:
```python
def create_cloudfunction_task(task_id: str, gcf_params: dict):
        endpoint_gcf = gcf_params['function_name']
        url_gcf = f"{URL_BASE_GCF}/{endpoint_gcf}"
        token_gcf = fetch_id_token(Request(), url_gcf)
        
        return HttpOperator(
            task_id=task_id,
            method=gcf_params.get("request_method", "POST"),
            http_conn_id=gcf_params.get("http_conn_id", "gcf_conn_id"),
            endpoint=endpoint_gcf,
            headers={'Authorization': f"Bearer {token_gcf}", "Content-Type": "application/json"},
            data=json.dumps(gcf_params['data_request']) if gcf_params.get('data_request') else None,
            trigger_rule=gcf_params.get('trigger_rule', 'all_success')
        )
```
Neste c√≥digo, os par√¢metros de requisi√ß√£o s√£o passados pelo atributo `data`.

#### **Documenta√ß√£o do Template**

Para entender os argumentos e aprender como utilizar o template `elt_data_pipeline.py`, consulte a documenta√ß√£o abaixo:
- [elt_data_pipeline](..\composer\plugins\include\template\elt_data_pipeline.py)

#### **2. Desenvolvimento Personalizado das DAGs**

Caso n√£o deseje utilizar o template √© poss√≠vel criar orquestra√ß√µes personalizadas, seguindo a documenta√ß√£o oficial do airflow com operadores para triggar uma Cloud Function com HttpOperator: 

- [Documenta√ß√£o Airflow HttpOperator](https://airflow.apache.org/docs/apache-airflow-providers-http/stable/operators.html).

## Jornada de Desenvolvimento

Durante o processo de desenvolvimento, vale destacar que o *rollout* (libera√ß√£o) e o *deploy* (implanta√ß√£o) das fun√ß√µes s√£o realizados automaticamente atrav√©s do GitHub Actions. Isso acontece sempre que um *push* √© feito na branch `dev`, acionando o deploy para o ambiente de desenvolvimento, ou na branch `main`, direcionando o deploy para o ambiente de produ√ß√£o.

‚ùó**Antes de prosseguir, por favor, assegure-se de revisar todos os t√≥picos anteriores.**

### Ambientes e Recursos Associados

Segue abaixo o link para acessar o console do Cloud Functions de cada projeto:

| Ambiente | Project ID | Console |
| --- | --- | --- |
| Desenvolvimento | ghm-data-dev | [cloudfunction-dev](https://console.cloud.google.com/functions/list?referrer=search&project=ghm-data-dev) |
| Produ√ß√£o | ghm-data-prod | [cloudfunction-prod](https://console.cloud.google.com/functions/list?referrer=search&project=ghm-data-prod) |

### Desenvolvimento

No processo de codifica√ß√£o da fun√ß√£o, recomenda-se a utiliza√ß√£o da linguagem Python. Essa orienta√ß√£o est√° alinhada a uma decis√£o estrat√©gica, levando em considera√ß√£o as caracter√≠sticas e vantagens espec√≠ficas do Python para o projeto.

#### Configura√ß√£o do Ambiente de Desenvolvimento Local
#### Requisitos

Certifique-se de ter os seguintes pr√©-requisitos instalados:

- [Google Cloud SDK](https://cloud.google.com/sdk)
- [Python](https://www.python.org/)
- [Poetry](https://python-poetry.org/docs/) - Opcional

#### Instala√ß√£o
Para a instala√ß√£o do projeto, siga as instru√ß√µes abaixo:

1. Clone o reposit√≥rio:

    ```bash
    git clone https://github.com/GitOpty/ghm-dados.git
    ```
2. Navegue at√© o diret√≥rio do projeto rec√©m-clonado:

    ```bash
    cd cloudfunctions
    ```
#### Utilizando `pip`

Se voc√™ preferir usar o `pip` para instalar as depend√™ncias, siga estas etapas:

1. **Cria√ß√£o e Ativa√ß√£o do Ambiente Virtual Python:**

    - No Linux:
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        ```

    - No Windows:
        ```bash
        python3 -m venv venv
        .\venv\Scripts\activate
        ```

2. **Instala√ß√£o dos Pacotes Python Necess√°rios:**

    Execute os seguintes comandos para instalar os pacotes listados nos arquivos `requirements.txt`

    ```bash
    pip install -r requirements.txt
    ```

#### Utilizando Poetry

Se voc√™ preferir usar o gerenciador de pacotes Poetry, siga estas etapas:

1. **Instala√ß√£o das Depend√™ncias com Poetry:**

    Instale as depend√™ncias do projeto usando Poetry:

    ```bash
    poetry install
    ```

2. **Ativa√ß√£o do Ambiente Virtual:**

    Ative o ambiente virtual criado pelo Poetry:

    ```bash
    poetry shell
    ```

#### Configura√ß√£o do Google Cloud SDK

- Baixe e instale o Google Cloud SDK (gcloud) do site do [Google Cloud](https://cloud.google.com/python/docs/reference?hl=pt-br).

- Inicialize o SDK com ``gcloud init`` para autenticar e configurar o acesso ao seu projeto do Google Cloud.

#### Prepara√ß√£o do Projeto Cloud Functions

##### Estrutura da Fun√ß√£o

- Crie um diret√≥rio para o seu projeto Cloud Function e navegue at√© ele.

- Dentro do diret√≥rio, crie um arquivo para o seu c√≥digo Python (por exemplo, main.py).

##### Gerenciamento de Depend√™ncias

- Crie um arquivo ``requirements.txt`` no diret√≥rio do projeto para listar todas as depend√™ncias necess√°rias. 

- Por exemplo, caso seja necess√°rio a lib ``requests``, adicione requests √† lista.
  - ```text
    request=={vers√£o}
    ```

- Instale as depend√™ncias no seu ambiente virtual usando ``pip install -r requirements.txt``.

#### Configura√ß√£o de Vari√°veis de Ambiente com Segredos do Secret Manager

Para configurar vari√°veis de ambiente com segredos armazenados no Secret Manager para cada fun√ß√£o, acesse o console do Cloud Functions e siga as instru√ß√µes da [documenta√ß√£o oficial](https://cloud.google.com/functions/docs/configuring/secrets?hl=pt-br).

‚ö†Ô∏è **Observa√ß√£o**: Nos scripts `var_{env}.sh`, os par√¢metros j√° foram implementados para automatizar a cria√ß√£o dessas vari√°veis de ambiente com base no Secret Manager. Basta configurar esses scripts para cada fun√ß√£o, facilitando a integra√ß√£o com os diferentes ambientes (desenvolvimento e produ√ß√£o).

#### Implanta√ß√£o

Para simplificar o processo de implanta√ß√£o das fun√ß√µes, foram desenvolvidos scripts que utilizam comandos **`gcloud`**, automatizando tanto a configura√ß√£o quanto o deploy no Google Cloud. Esse processo de deploy foi integrado ao pipeline de CI/CD via GitHub Actions, garantindo que toda a implanta√ß√£o seja realizada de forma cont√≠nua e automatizada. Portanto para realizar o deploy no ambiente de dev, basta realizar um push na branch `dev` deste reposit√≥rio.

Para implanta√ß√£o manual via console, consulte o [Guia R√°pido do Console do Google Cloud](https://cloud.google.com/functions/docs/console-quickstart?hl=pt-br).

#### Escolha um Modelo de DAG

Existem duas op√ß√µes principais para criar a DAG no Composer:

- **Template DAGs:** Use o template de DAG `elt_data_pipeline` referenciado acima. Este √© um modelo predefinido que pode ser configurado rapidamente com argumentos espec√≠ficos para o seu caso de uso.
- **DAG Personalizada:** Construa uma DAG personalizada para atender √†s suas necessidades espec√≠ficas, utilizando a documenta√ß√£o oficial do Airflow referenciada acima.

#### Teste de DAG

- Execute sua DAG no Composer e verifique os logs para garantir que a tarefa Cloud Function est√° sendo executada corretamente.

### Produ√ß√£o

Ao implementar as Fun√ß√µes em produ√ß√£o, siga estas instru√ß√µes:

1. **Implementa√ß√£o Automatizada**
    - Ap√≥s concluir os testes no ambiente de desenvolvimento, abra um *merge request* da branch `dev` para a branch `main`. Ap√≥s a aprova√ß√£o, o processo de deploy ser√° iniciado automaticamente. Aguarde a finaliza√ß√£o do deploy para o ambiente de produ√ß√£o antes de prosseguir.
3. **Revis√£o Cont√≠nua**
    - Mantenha uma pr√°tica cont√≠nua de revis√£o de c√≥digo para incorporar melhorias e corre√ß√µes √† medida que novas funcionalidades s√£o adicionadas ou requisitos evoluem.
4. **Documenta√ß√£o**
    - Mantenha a documenta√ß√£o atualizada, refletindo as mudan√ßas e atualiza√ß√µes implementadas nas Cloud Functions.

A jornada de desenvolvimento, seguindo os padr√µes estabelecidos, desde o ambiente de desenvolvimento at√© a produ√ß√£o, visa garantir que as Cloud Functions sejam desenvolvidas, testadas e implementadas de maneira eficiente, mantendo a consist√™ncia e a confiabilidade em todo o ciclo de vida do projeto.